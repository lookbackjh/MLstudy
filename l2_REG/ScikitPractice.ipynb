{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example of Minmax Featurization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin ## inheritance..\n",
    "class Minmaxreg(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,a) -> None:\n",
    "        self.a=a\n",
    "    def fit(self,X):\n",
    "        self.X_max=np.max(X)\n",
    "        self.X_min=np.min(X)\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        \n",
    "        try:\n",
    "            getattr(self, \"X_min\") or getattr(self,\"X_max\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        X=X.copy()\n",
    "        X=(X-self.X_min)/(self.X_max-self.X_min)\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_reg: [0.         0.11111111 0.22222222 0.33333333 0.44444444 0.55555556\n",
      " 0.66666667 0.77777778 0.88888889 1.        ]\n",
      "X_test_reg: [0.  0.5 1. ]\n"
     ]
    }
   ],
   "source": [
    "X_train=[1,2,3,4,5,6,7,8,9,10]\n",
    "X_test=[1,3,5]\n",
    "temp=4\n",
    "scale=Minmaxreg(temp)\n",
    "scale.fit(X_train)\n",
    "print(\"X_train_reg: {}\".format(scale.transform(X_train))) ## 결과 1\n",
    "\n",
    "scale.fit(X_test)\n",
    "print(\"X_test_reg: {}\".format(scale.transform(X_test))) ## 결과 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_reg: [0.         0.11111111 0.22222222 0.33333333 0.44444444 0.55555556\n",
      " 0.66666667 0.77777778 0.88888889 1.        ]\n",
      "X_test_reg: [0.         0.22222222 0.44444444]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"X_train_reg: {}\".format(scale.fit_transform(X_train))) ## 결과 1\n",
    "print(\"X_test_reg: {}\".format(scale.transform(X_test))) ## 결과 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Minmaxreg(a=1653245)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.get_params()\n",
    "scale.set_params(**{'a':1653245})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ridge Rigression class\n",
    "\n",
    "아래코드는 본강의 의 HW-2 에있는 ridge_regression.py를 그대로 작성한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from scipy.optimize import minimize\n",
    "from setup_problem import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gradient import *\n",
    "class RidgeRegression(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" ridge regression\"\"\"\n",
    "\n",
    "    def __init__(self, l2reg=1):\n",
    "        if l2reg < 0:\n",
    "            raise ValueError('Regularization penalty should be at least 0.')\n",
    "        self.l2reg = l2reg\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        n, num_ftrs = X.shape\n",
    "        # convert y to 1-dim array, in case we're given a column vector\n",
    "        y = y.values.reshape(-1,1)\n",
    "        def ridge_obj(w):\n",
    "            predictions = np.dot(X,w)\n",
    "            residual = y - predictions\n",
    "            empirical_risk = np.sum(residual**2) / n\n",
    "            l2_norm_squared = np.sum(w**2)\n",
    "            objective = empirical_risk + self.l2reg * l2_norm_squared\n",
    "            return objective\n",
    "        self.ridge_obj_ = ridge_obj\n",
    "\n",
    "        w_0 = np.zeros(num_ftrs)\n",
    "        self.w_ = minimize(ridge_obj, w_0).x\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"w_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        return np.dot(X, self.w_)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        # Average square error\n",
    "        try:\n",
    "            getattr(self, \"w_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        residuals = self.predict(X) - y\n",
    "        return np.dot(residuals, residuals)/len(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 Gradient Descent 를 구현 했을때, 사용했던 데이터를 그대로 이용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00475374 0.0047071  0.00482957 0.00479079 0.0050229  0.00479994\n",
      " 0.00465231 0.00496294 0.00504756 0.00511747 0.00480354 0.00447414\n",
      " 0.0049363  0.00502942 0.00464461 0.00501888 0.00476037 0.00460954\n",
      " 0.004786   0.00491225 0.00352897 0.00515757 0.00472208 0.00487714\n",
      " 0.00502122 0.00460349 0.00489362 0.00474189 0.00497075 0.00516706\n",
      " 0.00486863 0.00479226 0.00494532 0.00494294 0.0047825  0.00478913\n",
      " 0.00462048 0.00356574 0.00477012 0.00486362 0.00354656 0.00486926\n",
      " 0.00482588 0.00522112 0.00474458 0.00515039 0.00358054 0.00480658\n",
      " 0.0049779  0.00451915 0.00465096 0.00352779 0.00495659 0.00501862\n",
      " 0.00462391 0.00507063 0.00485641 0.0046842  0.00504393 0.00477464\n",
      " 0.00488952 0.00470381 0.00506592 0.00506863 0.00474172 0.0049091\n",
      " 0.00475167 0.0045377  0.00491403 0.00482927 0.00469954 0.00473265\n",
      " 0.00456736 0.00504039 0.00466602 0.00450052 0.00353932 0.00529552\n",
      " 0.0049423  0.00496112 0.00471978 0.00512093 0.00483424 0.00475041\n",
      " 0.00474181 0.00495659 0.00356711 0.00490377 0.00510273 0.0044957\n",
      " 0.00505615 0.00473041 0.00501115 0.00357177 0.00481144 0.00514132\n",
      " 0.00482904 0.00491125 0.00483946 0.0047954  0.00503809 0.00504723\n",
      " 0.00469398 0.00475089 0.00485594 0.00494623 0.00460453 0.00476456\n",
      " 0.00485605 0.00503556 0.00473448 0.0049884  0.00485878 0.00500027\n",
      " 0.00476069 0.00504487 0.00463597 0.00476359 0.00508874 0.00473146\n",
      " 0.00352838 0.00489967 0.00462754 0.00484828 0.0047423  0.00509346\n",
      " 0.00477339 0.00523668 0.00474011 0.0049576  0.00486638 0.00496151\n",
      " 0.00485178 0.00489569 0.0047588  0.00458365 0.00481393 0.00449831\n",
      " 0.00468752 0.00500195]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas\n",
    "\n",
    "df=pandas.read_csv(\"data.csv\") ## Jupiter Notebook이라 간단하게 표현가능, 실제로는 경로를 더 자세하게 표시해줘야함.\n",
    "y=df['y']\n",
    "X=df.loc[:,df.columns!='y']\n",
    "X_train,X_test,y_train,y_test=splitData(X,y)\n",
    "## 성능 평가를 위해 test set 과 train set을 분리.\n",
    "X_train,X_test=featurescale(X_train,X_test)\n",
    "ridge=RidgeRegression(l2reg=0.1)\n",
    "print(ridge.fit(X_train,y_train).predict(X_train))\n",
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
